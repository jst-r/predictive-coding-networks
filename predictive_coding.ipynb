{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa: F722"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "from torch.nn import functional as F\n",
    "%env PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from einops import rearrange, reduce, repeat\n",
    "\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jaxtyping import Float, jaxtyped\n",
    "from typeguard import typechecked\n",
    "from typing import List\n",
    "typechecker = typechecked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "def relu_gradient(x: t.Tensor):\n",
    "    return t.where(x > 0, t.ones_like(x), t.zeros_like(x))\n",
    "\n",
    "\n",
    "def sigmoid_gradient(x: t.Tensor):\n",
    "    return t.sigmoid(x) * (1 - t.sigmoid(x))\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PCNConfig:\n",
    "    learning_rate = 0.1\n",
    "    integration_step = 0.01\n",
    "    n_relaxation_steps = 8\n",
    "\n",
    "\n",
    "class PCN:\n",
    "    def __init__(self, cfg: PCNConfig, shape: List[int], device=\"cuda:0\") -> None:\n",
    "        self.cfg = cfg\n",
    "        self.n_layers = len(shape)\n",
    "        self.shape = shape\n",
    "        assert (\n",
    "            self.n_layers >= 2\n",
    "        ), \"at least two dims are required (input dimension and output dimension)\"\n",
    "\n",
    "        self.device = t.device(device)\n",
    "        with self.device:\n",
    "            in_dim, *hidded, out_dim = shape\n",
    "\n",
    "            self.activations = [None for _ in range(self.n_layers)]  # type: List[t.Tensor | None]\n",
    "\n",
    "            self.errors = [None for _ in range(self.n_layers)]  # type: List[t.Tensor | None]\n",
    "\n",
    "            self.weights = [\n",
    "                t.nn.init.xavier_normal_(t.empty(from_, to))\n",
    "                for [from_, to] in zip(shape, shape[1:])\n",
    "            ]\n",
    "\n",
    "            self.activation_fn = t.sigmoid\n",
    "            self.activation_fn_gradient = sigmoid_gradient\n",
    "\n",
    "    # @jaxtyped(typechecker=typechecker)\n",
    "    # def error_prediction(\n",
    "    #     x0: Float[t.Tensor, \"batch act0\"],\n",
    "    #     x1: Float[t.Tensor, \"batch act1\"],\n",
    "    #     w: Float[t.Tensor, \"act0 act1\"],\n",
    "    #     f,\n",
    "    # ) -> Float[t.Tensor, \"batch act1\"]:\n",
    "    #     # Eq 11\n",
    "    #     return x1 - w.matmul(f(x0))\n",
    "\n",
    "    # @jaxtyped(typechecker=typechecker)\n",
    "    # def weight_dynamics_step(\n",
    "    #     e0: Float[t.Tensor, \"batch act0\"],\n",
    "    #     e1: Float[t.Tensor, \"batch act1\"],\n",
    "    #     x0: Float[t.Tensor, \"batch act0\"],\n",
    "    #     w: Float[t.Tensor, \"act0 act1\"],\n",
    "    #     df,\n",
    "    # ) -> Float[t.Tensor, \"batch act0\"]:\n",
    "    #     return -e0 + t.dot(df(x0), t.matmul(w, e1))\n",
    "\n",
    "    def relaxation_step(self):\n",
    "        x = self.activations\n",
    "        e = self.errors\n",
    "        w = self.weights\n",
    "        f = self.activation_fn\n",
    "        df = self.activation_fn_gradient\n",
    "\n",
    "        for i in range(0, self.n_layers - 1):\n",
    "            # Eq 11\n",
    "            e[i + 1] = x[i + 1] - f(x[i]).matmul(w[i])\n",
    "\n",
    "        for i in range(1, self.n_layers - 1):\n",
    "            # Eq 12\n",
    "            dx = -e[i] + t.einsum(\"bi,bi->bi\", df(x[i]), t.matmul(w[i], e[i + 1].T).T)\n",
    "            x[i] = x[i] + self.cfg.integration_step * dx\n",
    "\n",
    "    def weight_update(self):\n",
    "        x = self.activations\n",
    "        e = self.errors\n",
    "        w = self.weights\n",
    "        f = self.activation_fn\n",
    "\n",
    "        for i in range(0, len(x) - 1):\n",
    "            dw = t.einsum(\"Bb,Ba->Bab\", e[i + 1], f(x[i])).mean(dim=0)\n",
    "            # ic(i, (dw * dw).mean(0).mean(0))\n",
    "            w[i] = w[i] + self.cfg.learning_rate * dw\n",
    "\n",
    "    def clear_activaitons(self, batch: int):\n",
    "        x = self.activations\n",
    "        with self.device:\n",
    "            for i in range(self.n_layers):\n",
    "                x[i] = t.zeros(batch, self.shape[i])\n",
    "\n",
    "    def forward(self, input_: t.Tensor):\n",
    "        self.clear_activaitons(input_.shape[0])\n",
    "        self.activations[0] = input_.to(self.device)\n",
    "\n",
    "        for _ in range(self.cfg.n_relaxation_steps):\n",
    "            self.relaxation_step()\n",
    "\n",
    "        return t.matmul(self.activations[-2], self.weights[-1])\n",
    "\n",
    "    def training_step(self, input_: t.Tensor, output: t.Tensor, n_relaxations_steps=32):\n",
    "        self.clear_activaitons(input_.shape[0])\n",
    "        self.activations[0] = input_.to(self.device)\n",
    "        self.activations[-1] = output.to(self.device)\n",
    "\n",
    "        for _ in range(self.cfg.n_relaxation_steps):\n",
    "            self.relaxation_step()\n",
    "\n",
    "        loss = F.mse_loss(\n",
    "            F.softmax(t.matmul((self.activations[-2]), self.weights[-1])), output\n",
    "        )\n",
    "\n",
    "        self.weight_update()\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define transformations for normalizing images\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            (0.1307,), (0.3081,)\n",
    "        ),  # Mean and standard deviation of MNIST\n",
    "    ]\n",
    ")\n",
    "\n",
    "    # Load training and test sets\n",
    "train_set = datasets.MNIST(\"data\", train=True, download=True, transform=transform)\n",
    "test_set = datasets.MNIST(\"data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# Create data loaders for batching\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " step 0\n",
      "loss tensor(0.0896, device='cuda:0')\n",
      "\n",
      " step 1\n",
      "loss tensor(0.0895, device='cuda:0')\n",
      "\n",
      " step 2\n",
      "loss tensor(0.0896, device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " step 3\n",
      "loss tensor(0.0896, device='cuda:0')\n",
      "\n",
      " step 4\n",
      "loss tensor(0.0895, device='cuda:0')\n",
      "\n",
      " step 5\n",
      "loss tensor(0.0895, device='cuda:0')\n",
      "\n",
      " step 6\n",
      "loss tensor(0.0896, device='cuda:0')\n",
      "\n",
      " step 7\n",
      "loss tensor(0.0895, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jstr\\AppData\\Local\\Temp\\ipykernel_22408\\2837893263.py:115: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  F.softmax(t.matmul((self.activations[-2]), self.weights[-1])), output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " step 8\n",
      "loss tensor(0.0895, device='cuda:0')\n",
      "\n",
      " step 9\n",
      "loss tensor(0.0896, device='cuda:0')\n",
      "\n",
      " step 10\n",
      "loss tensor(0.0896, device='cuda:0')\n",
      "\n",
      " step 11\n",
      "loss tensor(0.0893, device='cuda:0')\n",
      "\n",
      " step 12\n",
      "loss tensor(0.0895, device='cuda:0')\n",
      "\n",
      " step 13\n",
      "loss tensor(0.0897, device='cuda:0')\n",
      "\n",
      " step 14\n",
      "loss tensor(0.0895, device='cuda:0')\n",
      "\n",
      " step 15\n",
      "loss tensor(0.0895, device='cuda:0')\n",
      "\n",
      " step 16\n",
      "loss tensor(0.0895, device='cuda:0')\n",
      "\n",
      " step 17\n",
      "loss tensor(0.0896, device='cuda:0')\n",
      "\n",
      " step 18\n",
      "loss tensor(0.0895, device='cuda:0')\n",
      "\n",
      " step 19\n",
      "loss tensor(0.0895, device='cuda:0')\n",
      "\n",
      " step 20\n",
      "loss tensor(0.0895, device='cuda:0')\n",
      "\n",
      " step 21\n",
      "loss tensor(0.0895, device='cuda:0')\n",
      "\n",
      " step 22\n",
      "loss tensor(0.0895, device='cuda:0')\n",
      "\n",
      " step 23\n",
      "loss tensor(0.0895, device='cuda:0')\n",
      "\n",
      " step 24\n",
      "loss tensor(0.0895, device='cuda:0')\n",
      "\n",
      " step 25\n",
      "loss tensor(0.0896, device='cuda:0')\n",
      "\n",
      " step 26\n",
      "loss tensor(0.0895, device='cuda:0')\n",
      "\n",
      " step 27\n",
      "loss tensor(0.0894, device='cuda:0')\n",
      "\n",
      " step 28\n",
      "loss tensor(0.0896, device='cuda:0')\n",
      "\n",
      " step 29\n",
      "loss tensor(0.0896, device='cuda:0')\n",
      "\n",
      " step 30\n",
      "loss tensor(0.0895, device='cuda:0')\n",
      "\n",
      " step 31\n",
      "loss tensor(0.0896, device='cuda:0')\n",
      "\n",
      " step 32\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 33\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 34\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 35\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 36\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 37\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 38\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 39\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 40\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 41\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 42\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 43\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 44\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 45\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 46\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 47\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 48\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 49\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 50\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 51\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 52\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 53\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 54\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 55\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 56\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 57\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 58\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 59\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 60\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 61\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 62\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 63\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 64\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 65\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 66\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 67\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 68\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 69\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 70\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 71\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 72\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 73\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 74\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 75\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 76\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 77\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 78\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 79\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 80\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 81\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 82\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 83\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 84\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 85\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 86\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 87\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 88\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 89\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 90\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 91\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 92\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 93\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 94\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 95\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 96\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 97\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 98\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 99\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 100\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 101\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 102\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 103\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 104\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 105\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 106\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 107\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 108\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 109\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 110\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 111\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 112\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 113\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 114\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 115\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 116\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 117\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 118\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 119\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 120\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 121\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 122\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 123\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 124\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 125\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 126\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 127\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 128\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 129\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 130\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 131\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 132\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 133\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 134\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 135\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 136\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 137\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 138\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 139\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 140\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 141\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 142\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 143\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 144\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 145\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 146\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 147\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 148\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 149\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 150\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 151\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 152\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 153\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 154\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 155\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 156\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 157\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 158\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 159\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 160\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 161\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 162\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 163\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 164\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 165\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 166\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 167\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 168\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 169\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 170\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 171\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 172\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 173\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 174\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 175\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 176\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 177\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 178\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 179\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 180\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 181\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 182\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 183\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 184\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 185\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 186\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 187\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 188\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 189\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 190\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 191\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 192\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 193\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 194\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 195\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 196\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 197\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 198\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 199\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 200\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 201\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 202\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 203\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 204\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 205\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 206\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 207\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 208\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 209\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 210\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 211\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 212\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 213\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 214\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 215\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 216\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 217\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 218\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 219\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 220\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 221\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 222\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 223\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 224\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 225\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 226\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 227\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 228\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 229\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 230\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 231\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 232\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 233\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 234\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 235\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 236\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 237\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 238\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 239\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 240\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 241\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 242\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 243\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 244\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 245\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 246\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 247\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 248\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 249\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 250\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 251\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 252\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 253\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 254\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 255\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 256\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 257\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 258\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 259\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 260\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 261\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 262\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 263\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 264\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 265\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 266\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 267\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 268\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 269\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 270\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 271\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 272\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 273\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 274\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 275\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 276\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 277\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 278\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 279\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 280\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 281\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 282\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 283\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 284\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 285\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 286\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 287\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 288\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 289\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 290\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 291\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 292\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 293\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 294\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 295\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 296\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 297\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 298\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 299\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 300\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 301\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 302\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 303\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 304\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 305\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 306\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 307\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 308\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 309\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 310\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 311\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 312\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 313\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 314\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 315\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 316\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 317\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 318\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 319\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 320\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 321\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 322\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 323\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 324\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 325\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 326\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 327\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 328\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 329\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 330\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 331\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 332\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 333\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 334\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 335\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 336\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 337\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 338\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 339\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 340\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 341\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 342\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 343\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 344\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 345\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 346\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 347\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 348\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 349\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 350\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 351\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 352\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 353\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 354\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 355\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 356\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 357\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 358\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 359\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 360\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 361\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 362\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 363\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 364\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 365\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 366\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 367\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 368\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 369\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 370\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 371\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 372\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 373\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 374\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 375\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 376\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 377\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 378\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 379\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 380\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 381\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 382\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 383\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 384\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 385\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 386\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 387\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 388\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 389\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 390\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 391\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 392\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 393\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 394\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 395\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 396\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 397\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 398\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 399\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 400\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 401\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 402\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 403\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 404\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 405\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 406\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 407\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 408\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 409\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 410\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 411\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 412\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 413\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 414\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 415\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 416\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 417\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 418\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 419\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 420\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 421\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 422\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 423\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 424\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 425\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 426\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 427\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 428\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 429\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 430\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 431\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 432\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 433\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 434\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 435\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 436\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 437\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 438\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 439\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 440\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 441\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 442\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 443\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 444\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 445\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 446\n",
      "loss tensor(nan, device='cuda:0')\n",
      "\n",
      " step 447\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m label \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mone_hot(label, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m step \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# print(\"e[-2 norm]\", model.errors[-1].norm())\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# print(\"x[-2] norm\", model.activations[-2].norm())\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# print(\"eigenvalue\", t.svd(model.weights[-1])[1])\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10000\u001b[39m:\n",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36mPCN.training_step\u001b[1;34m(self, input_, output, n_relaxations_steps)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivations[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mn_relaxation_steps):\n\u001b[1;32m--> 112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelaxation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(\n\u001b[0;32m    115\u001b[0m     F\u001b[38;5;241m.\u001b[39msoftmax(t\u001b[38;5;241m.\u001b[39mmatmul((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivations[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweights[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])), output\n\u001b[0;32m    116\u001b[0m )\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_update()\n",
      "Input \u001b[1;32mIn [63]\u001b[0m, in \u001b[0;36mPCN.relaxation_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m     e[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m x[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m f(x[i])\u001b[38;5;241m.\u001b[39mmatmul(w[i])\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;66;03m# Eq 12\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     dx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241;43m-\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbi,bi->bi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     x[i] \u001b[38;5;241m=\u001b[39m x[i] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mintegration_step \u001b[38;5;241m*\u001b[39m dx\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = PCN(PCNConfig(), [784, 33, 16, 10])\n",
    "\n",
    "\n",
    "for [i, [input_, label]] in enumerate(train_loader):\n",
    "    input_ = input_.flatten(-3, -1).to(model.device)\n",
    "    label = F.one_hot(label, num_classes=10).to(model.device)\n",
    "\n",
    "    print(f\"\\n step {i}\")\n",
    "    print(\"loss\", model.training_step(input_, label))\n",
    "    # print(\"e[-2 norm]\", model.errors[-1].norm())\n",
    "    # print(\"x[-2] norm\", model.activations[-2].norm())\n",
    "    # print(\"eigenvalue\", t.svd(model.weights[-1])[1])\n",
    "\n",
    "    if i > 10000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image, label = batch\n",
    "image = image.flatten(0, -1) # batch in not handeled rn\n",
    "model.forward(image)\n",
    "model.weights[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.activations[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        ...,\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan],\n",
       "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.matmul(model.activations[-2], model.weights[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296,  0.64495873,  1.9305104 ,  1.5995764 ,\n",
       "        1.4977505 ,  0.33948106,  0.03400347, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        2.401455  ,  2.8087585 ,  2.8087585 ,  2.8087585 ,  2.8087585 ,\n",
       "        2.6432915 ,  2.0959773 ,  2.0959773 ,  2.0959773 ,  2.0959773 ,\n",
       "        2.0959773 ,  2.0959773 ,  2.0959773 ,  2.0959773 ,  1.7395868 ,\n",
       "        0.23765521, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296,  0.42857873,  1.0268056 ,\n",
       "        0.49221992,  1.0268056 ,  1.6504892 ,  2.4650962 ,  2.8087585 ,\n",
       "        2.4396398 ,  2.8087585 ,  2.8087585 ,  2.8087585 ,  2.7578456 ,\n",
       "        2.4905527 ,  2.8087585 ,  2.8087585 ,  1.3577399 , -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.20783298,  0.41585052, -0.2460177 ,  0.42857873,\n",
       "        0.42857873,  0.42857873,  0.32675284, -0.15692005,  2.5796502 ,\n",
       "        2.8087585 ,  0.9249798 , -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296,  0.63223046,  2.7960303 ,  2.235988  , -0.19510475,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.14419182,  2.5414655 ,\n",
       "        2.8214867 ,  0.63223046, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296,  1.2177293 ,  2.8087585 ,  2.6051068 ,  0.13582934,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296,  0.32675284,  2.7451172 ,\n",
       "        2.8087585 ,  0.36493754, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296,  1.2686423 ,  2.8087585 ,  1.9559668 , -0.3605718 ,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.30965886,  2.185075  ,\n",
       "        2.732389  ,  0.3140246 , -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296,  1.1795444 ,  2.8087585 ,  1.8923256 , -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296,  0.5304046 ,  2.7705739 ,\n",
       "        2.6305633 ,  0.30129635, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.1823765 ,  2.3887267 ,  2.8087585 ,  1.688674  , -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.38602826,  2.1596186 ,  2.8087585 ,\n",
       "        2.3632703 ,  0.02127524, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        0.05945994,  2.8087585 ,  2.8087585 ,  0.55586106, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.02963771,  2.4269114 ,  2.8087585 ,\n",
       "        1.0395339 , -0.41148472, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        1.2686423 ,  2.8087585 ,  2.8087585 ,  0.23765521, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296,  0.3522093 ,  2.6560197 ,  2.8087585 ,\n",
       "        2.8087585 ,  0.23765521, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "        1.1159033 ,  2.8087585 ,  2.8087585 ,  2.3632703 ,  0.08491641,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296,  1.1159033 ,  2.8087585 ,\n",
       "        2.2105315 , -0.19510475, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296, -0.42421296,\n",
       "       -0.42421296, -0.42421296, -0.42421296, -0.42421296], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.detach().cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
